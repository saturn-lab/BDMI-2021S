# 教学目标

- TensorFlow 2
  - 张量、变量
  - 计算图
  - 自动微分（原理）
  - 模型
  - 训练循环
  - 计算图、即刻执行
- Keras初步



# 微分

- 求导运算
  - 数值微分 Numerical differentiation
    - 根据导数定义来算
    - 准确率较低
  - 符号微分 Symbolic Differentiation
    - 将求导变为符号的推演
    - 定义基本的导数，在进行复合
    - 计算效率不高

![image-20210330134357196](/Users/chachali/Library/Application Support/typora-user-images/image-20210330134357196.png)

- 自动微分 Automatic Differentiation
  - 前向模式
    - 前向模式的二元数方法
  - 反向模式
    - 反向模式的反向计算图方法
    - 其他（历史）
      - 控制理论社群
      - 连续形式化
      - 离散形式（Werbos，1974）
- 反向传播与自动微分
- 静态图&动态图



![image-20210330134048780](/Users/chachali/Library/Application Support/typora-user-images/image-20210330134048780.png)



## 自动微分 / 前向模式 forward mode

![image-20210330134926790](/Users/chachali/Library/Application Support/typora-user-images/image-20210330134926790.png)

![image-20210330135210149](/Users/chachali/Library/Application Support/typora-user-images/image-20210330135210149.png)

将每一步都单独写出；

（每一步都是对x1进行求导）

缺点：

- 计算输出对**某个**输入的微分



前向模式基于对偶数的实现 Dual Numbers



## 自动微分 / 反向模式 reverse mode

优点：

- 计算输出对于所有输入的微分值



注意⚠️：反向模式与反向传播

反向传播图例：

![image-20210330140114762](/Users/chachali/Library/Application Support/typora-user-images/image-20210330140114762.png)



反向传播存在的问题

- 需要保存中间的计算数值，会消耗较大的存储空间

优化方案

- 构建反向计算图

![image-20210330140608059](/Users/chachali/Library/Application Support/typora-user-images/image-20210330140608059.png)

- 反向计算图构建算法

![image-20210330140626144](/Users/chachali/Library/Application Support/typora-user-images/image-20210330140626144.png)

- 算法思路

  ![image-20210330140738015](/Users/chachali/Library/Application Support/typora-user-images/image-20210330140738015.png)

  - 查找C的所有依赖节点，并计算C的梯度，插入新的计算图中
  - 反向拓扑图的顺序（reverse_topo_order）

  

![image-20210330140836160](/Users/chachali/Library/Application Support/typora-user-images/image-20210330140836160.png)

自动微分的反向模式：

![image-20210330141011477](/Users/chachali/Library/Application Support/typora-user-images/image-20210330141011477.png)



## 静态和动态的反向计算图



# Python 面向对象编程

- 类 Class
- 对象 Object
- 属性 Attribute
- 方法 Method - 类可以实现一个操作
- 参数 Parameters - 影响方法行为的输入
- 实例化 Instance - 根据某个抽象类创建具体对象的过程



Python 类 `__init__` 函数

（构造函数）

``` python
class student (people):
  def __init__(self, n, a, w, g):
    people.__init__(self, n, a)
    self.grade = g
    
  def speak(self):
    print()
    
s = student('Ken', 10, 60, 3)
```

![image-20210330143426217](/Users/chachali/Library/Application Support/typora-user-images/image-20210330143426217.png)



`super()`

子类对象调用父类已被覆盖的方法

```
class cat:
    def speak(self):
        print('I\'m a cat.')

class blackcat(cat):
    def speak(self):
        print('I\'m a black cat.')

c = blackcat()

c.speak()

super(blackcat,c).speak()
```



```__call()__`` 方法



类实例化出实例后，```实例名()``` 将调用```call()```方法



# TensorFlow2 模块、层、模型 Modules/Layers/Model

- 模块（定义、保存、恢复）
  - 对张量进行计算的函数（前向运算）
  - 变量在训练过程中被更新
- 在TensorFlow中定义模型和层
  - 层：可重用的带参数的结构
  - 所有模型和层都是tf.Module的派生类
- tensorboard：
  - 对TensorFlow模型和张量进行可视化的工具

## 模块 Module

![image-20210330145223076](/Users/chachali/Library/Application Support/typora-user-images/image-20210330145223076.png)

## 层 Dense

![image-20210330145545204](/Users/chachali/Library/Application Support/typora-user-images/image-20210330145545204.png)



`in_features`

`out_features`

定义两个参数 w 和 b

return时给一个激活函数



![image-20210330152257293](/Users/chachali/Library/Application Support/typora-user-images/image-20210330152257293.png)

![image-20210330152555906](/Users/chachali/Library/Application Support/typora-user-images/image-20210330152555906.png)

第二个的in_features需要和第一个的out_features设为相同的值



## 动态决定张量维度

![image-20210330153712099](/Users/chachali/Library/Application Support/typora-user-images/image-20210330153712099.png)

![image-20210330153832124](/Users/chachali/Library/Application Support/typora-user-images/image-20210330153832124.png)



## 模型存储和恢复

- 存储

Api: `checkpoint`

参数：model

checkpoint.write(chip_path)

- 恢复

new_model =

tf.train.Checkpoint

.restore



使用装饰器

`@tf.function`

写在 `def __call__` 前面



## tensorboard 可视化



![image-20210330154548391](/Users/chachali/Library/Application Support/typora-user-images/image-20210330154548391.png)



# 计算图



## Graph 概念

- 定义各种变量
- 变量间通过操作符建立计算关系
- tensorflow建立计算图



- 由 nodes（变量 或 Operator） 和 edges（计算间的依赖） 组成

- 实现表示有数据传递依赖
- 虚线通常表示执行的先后顺序



## Graph 建立

- `tf.function`

![image-20210330155436694](/Users/chachali/Library/Application Support/typora-user-images/image-20210330155436694.png)

- （使用装饰器）

![image-20210330155718666](/Users/chachali/Library/Application Support/typora-user-images/image-20210330155718666.png)

- 利用Tensorboard显示图: `%load_ext tensorboard`
- 创建日志 `import datetime`
- `stamp`
- `logdir`

![image-20210330160020893](/Users/chachali/Library/Application Support/typora-user-images/image-20210330160020893.png)

## Graph 的加速



# 训练流程

1. 获取训练数据

2. 定义模型

   1. 用变量表示权重和偏置
   2. 给出初始值
   3. 使用模块封装变量和计算
   4. 验证模型的有效性

   ![image-20210330161538859](/Users/chachali/Library/Application Support/typora-user-images/image-20210330161538859.png)

3. 定义损失函数

4. 运行训练数据从目标值计算损失（由重复执行的任务组成）

   1. 通过发送一批输入到模型中以生成输出
   2. 通过生成的输出与目标输出的比较来计算损失
   3. 使用GradientTape计算损失loss对权重w的梯度
   4. 用梯度优化变量w, b

5. 计算损失的梯度，并使用优化器来调整变量以适应数据

6. 结果评估



# 使用Keras模型

![image-20210330162416061](/Users/chachali/Library/Application Support/typora-user-images/image-20210330162416061.png)





# 课后阅读

![image-20210330141430944](/Users/chachali/Library/Application Support/typora-user-images/image-20210330141430944.png)



# 遗留问题

![image-20210330144851070](/Users/chachali/Library/Application Support/typora-user-images/image-20210330144851070.png)

