## 数据流水线 tf.data

### 读取数据

- tf.data.Dataset
  - from_generator ---可以减少内存开销
  - TextLineDataset ----读取文本txt
  - experimental.make_csv_dataset --读取表格
- shuffle（）---数据打乱
- 数据预处理
  - 自定义预处理函数后利用dataset.map(预处理函数名)
- 对类别不平衡数据的处理--以指定的比例从样本集中采样

## 函数式API

- 输入与输出的变换，比顺序模型更加灵活，且处理范围广泛（非线性拓扑、具有共享层均可）
- 可以用单个层计算图生成多个模型
- 所有模型可以像层一样被调用
- 复杂计算图模型与共享层
  - embedding（嵌入）-能实现文本转化为数字
- 残差网络
  - 不是完全线性推进，存在跳跃连接，实现f2(x)=f(x)+x

# 循环网络 RNN

## **基本结构**

- 循环网络---有反馈链接，是反馈网络的一种
- 记忆网络---单个神经元当前时刻的输入可以是此前该神经元任意时刻的输出
- 特点
  - 有时间维度，每个时间点用相同的权重（时间维度上的权重共享）
  - 可以在时间步上展开得到计算图
- 基本循环网络
  - 反馈链接在隐藏层：隐藏层对下一时刻的隐藏层是全连接的
    - h(t)=Wh(t-1)+Ux(t)+b 再激活
  - 损失是总损失，即每个o与对应标签的差别之和
  - BPTT（通过时间的反向传播算法）
    - 正向算出损失，再反向调节参数，复杂度是O(T)
    - 每个时间步只能一前一后的算，前向的参数也要保存，内存也是o(T)

## 循环网络变种-长短时记忆网络 lstm

- LSTM解决基本循环网络收敛慢的问题
- 3个门，1个记忆单元
  - 输入门
  - 遗忘门
  - 输出门
- 核心--记忆单元的加入，增加了反向梯度运算的计算路径