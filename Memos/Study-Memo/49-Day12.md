## 学习概览

1. Seq2Seq 序列对序列模型

2. 神经网络机器翻译NMT（Neural Machine Translation）

   编码器和解码器架构（encoder-decoder）

   编码器将输入语句转换为一个中间向量

   解码器将中间向量转换为翻译的结果

3. Text generation with rnn

   random sampling

4. Attention Intuition & Transformer Overview

5. BERT introduction

   BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, 

6. Audio Recogniton

   Spectrogram using stft

