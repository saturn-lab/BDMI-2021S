# # study memo week 1

#### 2017080040 松本博晓 16



## numpy的用法

reshape

![image-20210309140238115](C:\Users\hiroaki\AppData\Roaming\Typora\typora-user-images\image-20210309140238115.png)

![image-20210309140719516](C:\Users\hiroaki\AppData\Roaming\Typora\typora-user-images\image-20210309140719516.png)







## 深度学习



1.人工神经元：

权重与偏置

激活函数（sigmoid、relu、tanh）

人工神经元实现布尔运算（与、或、非、异或）

## 课堂练习 sigmoid 函数

```
import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

print(sigmoid(5))
```



2.神经网络简介：

分类任务与回归任务

$softmax$、分对数模型

损失函数（均方差、交叉熵）





## 其他

## 课堂练习 tanh 函数



## max函数

0需要放在后面，否则会报错

np.max(-0.21*x1 +0.3*x2+0.7*x3,0)



----

## lambda 函数的用法

下面两个写法相同

```
sigmoid= lambda x :1 / (1 + np.exp(-x))

def sigmoid(x):
    return 1 / (1 + np.exp(-x))
```

