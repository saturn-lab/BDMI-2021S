# 卷积网络与TensorFlow2-Keras学习



CNN

RNN

# Keras模型的保存和加载

## 保存SavedModel

- 架构
- 权重
- 编译信息
- 优化器



保存 架构&权重

保存 （仅）架构

保存 （仅）权重

保存 配置 （架构+编译信息-e.g.损失函数、学习率）



函数式API - 顺序模型的推广



# 多层神经网络

全连接网络的参数问题

问题：参数量过大



![image-20210413140121952](/Users/chachali/Library/Application Support/typora-user-images/image-20210413140121952.png)





# 卷积网络

## 卷积网络的基本结构

前馈网络

部分连接



### 卷积核与卷积计算

- 卷积核 kernel/Filter - 一个多维数组
  - 参数由学习算法得到
  - 卷积核数目一般选32、64等
- padding
- 对图片运行较多
- 卷积Convolution是一种张量运算



### 1d 2d 3d 卷积核

depth - 卷积核的个数



归一化层

限制在0-1之间的分布



局部连接 + 权重共享



![image-20210413144932651](/Users/chachali/Library/Application Support/typora-user-images/image-20210413144932651.png)



## 卷积网络发展深度



## 卷积网络应用



## 卷积网络-小结

●卷积网络的基本的结构（a series of stages of the form）：

○卷积层（Convolutional Layers）

○非线性激活单元Non-linearityactivation(ReLU or sigmoid functions)

○池化层（Pooling）

○随机丢弃层（Dropout）

●权重共享（Parameters sharing）和池化（pooling）操作作用

○利用了波形或图像信息的局部和谐性（local coherence）

○学习其中的不变量特征（invariant features）

•卷积网络优点：

•计算快，参数的个数少，可以并行化



## AlexNet 卷积网络

•AlexNet的图像分类准确度大幅提升的原因：

○层数更深：8层网络vs. 3层网络

○参数更多：6千万参数vs. 1百万参数

○硬件更快：采用GPU来做训练

○数据集更大：1.2百万的图片集和而不是之前的上千大小的数据集

○更好的正则化：采用随机丢弃（dropout ）技术



## 图像分类-多个Dense层网络实现

•多层感知机MLP (Multi-Layer-Perceptron) 是一个常用的分类器（Classifier），由多个Dense层网络组成

•MLP进行图像分类（Image Classification）参数估计

•彩色图像的每个像素点的颜色由RGB值表示，一张200x200x3的图片

•采用全连接Dense层，单个神经元有200*200*3 = 120,000参数!

•如果用3层网络，每层10个神经元

•共计3,600,000个参数

•MLP做图像分类，参数量太大！



## 人脸辨识与识别

![image-20210420132530559](/Users/chachali/Library/Application Support/typora-user-images/image-20210420132530559.png)

