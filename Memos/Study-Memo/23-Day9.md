# WW9课程小结

04.20

循环网络 Recurrent Neural Network

### 数据流水线

tf.data读取数据

`dataset.shuffle()` 打乱数据

`dataset.map(function)` 数据预处理

`tf.data.experimental.sample_from_datasets() ` 处理不平衡类别的数据

from_tensor_slices 得到字符串数据集

tf.data

### 函数式API

输入到输出的变换

模型摘要 `model.summary()`

#### 层和模型

模型是层的组合，还有fit ，训练，predict等

+ 可以使用单个层计算图生成多个模型
+ 所有模型均可像层一样调用

+ 具有多个输入和输出的模型
+ *残差网络

## 循环网络

有反馈链接

扩展：记忆网络

### RNN基本结构

在时间维度，每一个时间相同权重同步处理

权重共享 weights sharing

+ UVW：采用相同权重矩阵
+ W：隐藏层到下一时刻隐藏层全连接权重矩阵

循环网络的训练：通过时间反向传播 BPTT

一次前向+反向传播 O(T)，内存也是O(T)，训练代价大

LSTM 

#### 双向RNN

backward layer 和 forward layer

### 长短时记忆网络 LSTM

门结构

输入门、遗忘门

记忆单元和输出门，为误差导数传播增加了一条路径

### 循环网络应用

诗歌创作

语音识别

